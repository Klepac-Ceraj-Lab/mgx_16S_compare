{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import janitor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in original data\n",
    "\n",
    "path = '/Users/danielle/Documents/thesis/subsampled_analysis/subsample_2_profiles/*'                     \n",
    "all_files = [name for name in glob.glob(path)]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/danielle/Documents/thesis/subsampled_analysis/subsample_2_profiles/C0005_3F_1A_1000k_1_profile.tsv\n",
      "/Users/danielle/Documents/thesis/subsampled_analysis/subsample_2_profiles/C0005_3F_1A_1000k_2_profile.tsv\n",
      "/Users/danielle/Documents/thesis/subsampled_analysis/subsample_2_profiles/C0005_3F_1A_1000k_3_profile.tsv\n",
      "/Users/danielle/Documents/thesis/subsampled_analysis/subsample_2_profiles/C0005_3F_1A_1000k_4_profile.tsv\n",
      "/Users/danielle/Documents/thesis/subsampled_analysis/subsample_2_profiles/C0005_3F_1A_100k_1_profile.tsv\n",
      "/Users/danielle/Documents/thesis/subsampled_analysis/subsample_2_profiles/C0005_3F_1A_100k_2_profile.tsv\n",
      "/Users/danielle/Documents/thesis/subsampled_analysis/subsample_2_profiles/C0005_3F_1A_100k_3_profile.tsv\n",
      "/Users/danielle/Documents/thesis/subsampled_analysis/subsample_2_profiles/C0005_3F_1A_100k_4_profile.tsv\n",
      "/Users/danielle/Documents/thesis/subsampled_analysis/subsample_2_profiles/C0005_3F_1A_10k_2_profile.tsv\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a67a9eb5c65b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# percent unclassified organisms profiled with mgx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0munclassified\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtaxa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_unclassified| noname | Candidatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0munclassified_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munclassified\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "df_from_each_file = []\n",
    "unclassified_list = []\n",
    "\n",
    "for f in all_files:\n",
    "    print(f)\n",
    "    df = pd.read_csv(f, sep = '\\t', skiprows=[0,1,2], usecols = ['#clade_name','relative_abundance']) # read in dataframe \n",
    "    \n",
    "    id_1 = f.split('profiles/')[1] # add sample id from filename \n",
    "    id_2 = id_1.split('_S')[0]\n",
    "    df[\"sampleid\"] = id_2\n",
    "    \n",
    "    df.rename(columns = {'#clade_name':'taxa', 'relative_abundance':'abundance'}, inplace = True) \n",
    "    \n",
    "    df = df[df['taxa'].str.contains(\"\\|g__\")] # keep genera\n",
    "    df = df[~df['taxa'].str.contains(\"\\|s__\")] # keep species\n",
    "    df[\"taxa\"] = df['taxa'].str.split(\"\\|g__\").str[-1]\n",
    "    df[\"taxa\"] = df['taxa'].str.split(\"\\|s__\").str[0]\n",
    "    \n",
    "    # percent unclassified organisms profiled with mgx\n",
    "    unclassified = sum(df.taxa.str.contains(\"_unclassified| noname | Candidatus\"))/df.shape[0]\n",
    "    unclassified_list.append(unclassified)\n",
    "    \n",
    "    # remove unclassified\n",
    "    df = df[~df.taxa.str.contains(\"_unclassified\")]\n",
    "    df = df[~df.taxa.str.contains(\"_noname\")]\n",
    "    df = df[~df.taxa.str.contains(\"Candidatus\")]\n",
    "    \n",
    "    # combine together taxa of the same genera\n",
    "    df = df.groupby(['taxa', 'sampleid'])['abundance'].sum().reset_index()    \n",
    "    \n",
    "    # convert to relative abundance\n",
    "    df[\"abundance\"] = df[\"abundance\"]/100.0\n",
    "    \n",
    "    df_from_each_file.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# averaging mean unclassified across all dataframes\n",
    "np.mean(unclassified_list)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.concat(df_from_each_file, ignore_index=True) # concat all dataframes together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_reshaped = original.pivot_table(index = \"sampleid\", values=\"abundance\", columns = \"taxa\") # pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_reshaped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_reshaped.columns.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_reshaped = original_reshaped.rename_axis(None, axis=1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_reshaped = original_reshaped.fillna(0)  # fill in missing values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_reshaped[\"uid\"] = original_reshaped[\"sampleid\"].astype(str)+'-original'# add unique identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_reshaped.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample = pd.read_csv(\"~/Documents/thesis/subsampled_analysis/merged_abundance_table.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample[\"ID\"][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep genera\n",
    "subsample = subsample[subsample['ID'].str.contains(\"\\|g__\")]\n",
    "subsample = subsample[~subsample['ID'].str.contains(\"\\|s__\")]\n",
    "subsample = subsample[~subsample['ID'].str.contains(\"\\|t__\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning genera name\n",
    "subsample[\"ID\"] = subsample['ID'].str.split(\"\\|g__\").str[-1]\n",
    "subsample[\"ID\"] = subsample['ID'].str.split(\"\\|s__\").str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_transposed = subsample.set_index('ID').transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_transposed.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_transposed.rename(columns = {'index':'sampleid'}, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_transposed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt dataframes\n",
    "subsample_melt = pd.melt(subsample, id_vars=[\"ID\"], var_name = \"sampleid\", value_name = \"abund\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_melt.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_melt[\"replicate\"] = subsample_melt['sampleid'].str.split(\"k_\").str[-1]\n",
    "subsample_melt[\"replicate\"] = subsample_melt['replicate'].str.split(\"_profile\").str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_melt[\"read_depth\"] = subsample_melt['sampleid'].str.split(\"1A_\").str[-1]\n",
    "subsample_melt[\"read_depth\"] = subsample_melt['read_depth'].str.split(\"k_\").str[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "subsample_melt.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_melt.to_csv('subsample_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add metadata to transposed dataframe\n",
    "subsample_transposed[\"replicate\"] = subsample_transposed['sampleid'].str.split(\"k_\").str[-1]\n",
    "subsample_transposed[\"replicate\"] = subsample_transposed['replicate'].str.split(\"_profile\").str[0]\n",
    "subsample_transposed[\"read_depth\"] = subsample_transposed['sampleid'].str.split(\"1A_\").str[-1]\n",
    "subsample_transposed[\"read_depth\"] =subsample_transposed['read_depth'].str.split(\"k_\").str[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_transposed['read_depth'] = (subsample_transposed['read_depth'].astype(str).astype(int))*1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_transposed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix '_' in sampleid, sample names\n",
    "subsample_transposed[\"sampleid\"] = subsample_transposed[\"sampleid\"].str.replace(\"_\",'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_transposed[\"uid\"] = subsample_transposed[\"sampleid\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_transposed[\"sampleid\"] = subsample_transposed[\"sampleid\"].str.split(\"-10\").str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_transposed.drop(columns=['replicate'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_transposed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mgx data\n",
    "original = pd.read_csv(\"~/Documents/thesis/analysis/mgx_abundance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_transposed = original.set_index(\"taxa\").transpose()\n",
    "original_transposed.reset_index(level=0, inplace=True)\n",
    "original_transposed.rename(columns = {'index':'sampleid'}, inplace = True) \n",
    "original_transposed[\"uid\"] = original_transposed[\"sampleid\"].astype(str)+'-original'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding age metadata\n",
    "age = pd.read_csv(\"~/Documents/thesis/theoretical/sorted_babies.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove shannon column, change characters in sample names \n",
    "age.drop(columns=['shannon'], inplace= True)\n",
    "age[\"sample\"] = age[\"sample\"].str.replace(\"_\",'-')\n",
    "age.rename(columns = {'sample':'sampleid', \"reads\":\"read_depth\"}, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make age dictionary\n",
    "agedict = {str(s): {} for s in age[\"sampleid\"]}\n",
    "for index, row in age.iterrows():\n",
    "    age_months = row[\"AgeMonths\"]\n",
    "    agedict[row[\"sampleid\"]]= age_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_depth dictionary\n",
    "readdict = {str(s): {} for s in age[\"sampleid\"]}\n",
    "for index, row in age.iterrows():\n",
    "    reads = row[\"read_depth\"]\n",
    "    readdict[row[\"sampleid\"]]= reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_stage dictionary\n",
    "dev_stage_dict = {str(s): {} for s in age[\"dev_stage\"]}\n",
    "for index, row in age.iterrows():\n",
    "    stage = row[\"dev_stage\"]\n",
    "    dev_stage_dict[row[\"sampleid\"]] = stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_reshaped[\"AgeMonths\"]= original_reshaped[\"sampleid\"].map(agedict)\n",
    "original_reshaped[\"read_depth\"]= original_reshaped[\"sampleid\"].map(readdict)\n",
    "original_reshaped[\"dev_stage\"]= original_reshaped[\"sampleid\"].map(dev_stage_dict)\n",
    "original_reshaped[\"sampling_cat\"] = \"original depth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_reshaped.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_transposed[\"AgeMonths\"]= subsample_transposed[\"sampleid\"].map(agedict)\n",
    "subsample_transposed[\"dev_stage\"]= subsample_transposed[\"sampleid\"].map(dev_stage_dict)\n",
    "subsample_transposed[\"sampling_cat\"] = subsample_transposed[\"read_depth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_transposed.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df = pd.concat([original_reshaped,subsample_transposed], sort=True).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "concat_df = concat_df.fillna(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_order = ['uid', 'sampleid', 'read_depth', 'AgeMonths', 'dev_stage', 'sampling_cat']\n",
    "new_columns = cols_to_order + (concat_df.columns.drop(cols_to_order).tolist())\n",
    "concat_df = concat_df[new_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove mothers\n",
    "# concat_df = concat_df[~concat_df.sampleid.str.contains(\"M\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.to_csv('subsampled_df_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
